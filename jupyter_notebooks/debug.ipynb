{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tunable_agents import utility, main\n",
    "import utils\n",
    "import gin\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tunable_agents.environments.gathering_env import gathering_env\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.agents import data_converter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_path = \"C:/Users/maler/Federico/Università/Master/Tesi\"\n",
    "configs_dir = \"C:/Users/maler/Google Drive/Personale/Università/Master/Tesi/Code/tunable-agents-MORL/configs/\"\n",
    "root_dir = absolute_path + \"/experiments_results\"\n",
    "experiment_name = \"gathering_replication\"\n",
    "experiment_dir = \"C:/Users/maler/Google Drive/Personale/Università/Master/Tesi/Code/experiments_results/\" + experiment_name\n",
    "policy_dir = os.path.join(root_dir, experiment_name, \"policy\")\n",
    "\n",
    "gin_files = [configs_dir + \"envs/gathering_replication_env.gin\"]\n",
    "gin_files += [configs_dir + \"gathering_replication.gin\", configs_dir + \"qnets/replication_qnet.gin\"]\n",
    "# gin_files = [configs_dir + \"envs/gathering_fixed_env.gin\"]\n",
    "gin_bindings = []\n",
    "utility.load_gin_configs(gin_files, gin_bindings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gathering_env.GatheringWrapper(utility_repr=np.array([1,5,3,4,5,6], dtype=np.float32))\n",
    "env = gathering_env.GatheringWrapper()\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "#env = gathering_env.GatheringWrapper(cumulative_rewards_flag=True)\n",
    "\n",
    "train_step = tf.Variable(0, trainable=False, name='global_step', dtype=tf.int64)\n",
    "epoch_counter = tf.Variable(0, trainable=False, name='Epoch', dtype=tf.int64)\n",
    "decaying_epsilon = utility.decaying_epsilon(step=epoch_counter)\n",
    "tf_agent = utility.create_agent(environment=tf_env, decaying_epsilon=decaying_epsilon, train_step_counter=train_step)\n",
    "\n",
    "replay_buffer = utility.create_replay_buffer(data_spec=tf_agent.collect_data_spec,\n",
    "                                             batch_size=tf_env.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_checkpoint_dir = os.path.join(experiment_dir, 'checkpoints', 'rb')\n",
    "rb_checkpointer = common.Checkpointer(ckpt_dir=rb_checkpoint_dir,\n",
    "                                        max_to_keep=1,\n",
    "                                        replay_buffer=replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\maler\\google drive\\personale\\università\\master\\tesi\\code\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:1218: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\maler\\google drive\\personale\\università\\master\\tesi\\code\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:1218: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "dataset = replay_buffer.as_dataset(single_deterministic_pass=False).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), observation=DictWrapper({'state_obs': TensorSpec(shape=(8, 8, 9), dtype=tf.float32, name=None), 'utility_representation': TensorSpec(shape=(4,), dtype=tf.float32, name=None)}), action=BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0), maximum=array(4)), policy_info=(), next_step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "print(tf_agent.collect_data_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.  ]\n",
      " [0.99 0.99]\n",
      " [0.   1.  ]\n",
      " [1.   0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.  ]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [1.   0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.  ]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.  ]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [0.99 0.99]\n",
      " [1.   0.99]]\n",
      "[[1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 2]\n",
      " [2 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 0]]\n"
     ]
    }
   ],
   "source": [
    "print(data[0].discount.numpy())\n",
    "print(data[0].step_type.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.125 0.5   0.5   0.25 ]\n",
      " [0.125 0.5   0.5   0.25 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data[0].observation['utility_representation'].numpy()[5])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(data[0].observation['state_obs'].numpy()[5][0][:,:,:3])\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(data[0].observation['state_obs'].numpy()[5][0][:,:,3:6])\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(data[0].observation['state_obs'].numpy()[5][0][:,:,6:])\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(data[0].observation['state_obs'].numpy()[5][1][:,:,:3])\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(data[0].observation['state_obs'].numpy()[5][1][:,:,3:6])\n",
    "plt.subplot(2,3,6)\n",
    "plt.imshow(data[0].observation['state_obs'].numpy()[5][1][:,:,6:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = data[0]\n",
    "as_transition = data_converter.AsNStepTransition(\n",
    "          self.data_context, gamma=gamma, n=n_step_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EncodingNetwork\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImagePreprocessing (Sequenti (1, 4096)                 611072    \n",
      "_________________________________________________________________\n",
      "utility_representation_Input multiple                  0         \n",
      "_________________________________________________________________\n",
      "concatenate (Concatenate)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  262464    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 877,696\n",
      "Trainable params: 877,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"QNetwork\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "EncodingNetwork (EncodingNet multiple                  877696    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  325       \n",
      "=================================================================\n",
      "Total params: 878,021\n",
      "Trainable params: 878,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tf_agent._q_network._encoder.summary())\n",
    "print(tf_agent._q_network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.engine.sequential.Sequential object at 0x00000232820622B0>, <tensorflow.python.keras.engine.sequential.Sequential object at 0x0000023282062850>, <tensorflow.python.keras.layers.merge.Concatenate object at 0x000002328206FCA0>, <tensorflow.python.keras.layers.core.Flatten object at 0x000002328206FFD0>, <tensorflow.python.keras.layers.core.Dense object at 0x00000232820785E0>, <tensorflow.python.keras.layers.core.Dropout object at 0x00000232820788B0>, <tensorflow.python.keras.layers.core.Dense object at 0x0000023282078910>, <tensorflow.python.keras.layers.core.Dropout object at 0x0000023282078CA0>]\n",
      "Model: \"ImagePreprocessing\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Convolutional (Conv2D)       (1, 6, 6, 256)            20992     \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (1, 6, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "Convolutional2 (Conv2D)      (1, 4, 4, 256)            590080    \n",
      "_________________________________________________________________\n",
      "Dropout2 (Dropout)           (1, 4, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (1, 4096)                 0         \n",
      "=================================================================\n",
      "Total params: 611,072\n",
      "Trainable params: 611,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(tf_agent._q_network._encoder.layers)\n",
    "tf_agent._q_network._encoder.layers[0].summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dropout, Dense, Flatten, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=(8,8,9))\n",
    "# preference weights\n",
    "weights_input = Input(shape=(4,)) # 4 weights\n",
    "\n",
    "# Define Layers\n",
    "x = image_input\n",
    "x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Concatenate()([x, weights_input])\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(5)(x)\n",
    "outputs = x\n",
    "\n",
    "# Build full model\n",
    "model = keras.Model(inputs=[image_input, weights_input], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8, 8, 9)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 6, 6, 256)    20992       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 6, 6, 256)    0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 4, 4, 256)    590080      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4, 4, 256)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 4096)         0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4100)         0           flatten_3[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           262464      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           4160        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 5)            325         dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 878,021\n",
      "Trainable params: 878,021\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = env.reset()\n",
    "action = None\n",
    "print(time_step.observation['utility_representation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7), dpi=100)\n",
    "for i in range(1, 4):\n",
    "    plt.subplot(1,3,i)\n",
    "    image = time_step.observation['state_obs'][:, :, 3*(i-1):3*i]\n",
    "    plt.imshow(image)\n",
    "    plt.title('Utility: {}    Action: {}'.format(time_step.reward, action))\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "if time_step.is_last():\n",
    "    print('END EPISODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: Do nothing\n",
    "# 1: Left\n",
    "# 2: Right\n",
    "# 3: Down\n",
    "# 4: Up\n",
    "action = 3\n",
    "\n",
    "\n",
    "time_step = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env._prev_step_utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
